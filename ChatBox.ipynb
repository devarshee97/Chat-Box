{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBox.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "24QdEstWKMcC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtQJohi21gK1",
        "outputId": "f9d7058a-3819-44e2-ce24-7bed030a4852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "import nltk\n",
        "import random\n",
        "import string\n",
        "import bs4 as bs\n",
        "import requests\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Extraction"
      ],
      "metadata": {
        "id": "npqbFPaoKWqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbxubC_pJk3X",
        "outputId": "8b370425-adfc-4e12-8545-b3ea885ecc97"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = requests.get('https://en.wikipedia.org/wiki/Cuisine')\n",
        "raw_html = r.text\n"
      ],
      "metadata": {
        "id": "G2T60PlV2t3r"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "ohBCIleaKaUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_html = bs.BeautifulSoup(raw_html)\n",
        "\n",
        "corpus_paras = corpus_html.find_all('p')\n",
        "corpus_text = ''\n",
        "\n",
        "for para in corpus_paras:\n",
        "  corpus_text += para.text\n",
        "\n",
        "corpus_text = corpus_text.lower()"
      ],
      "metadata": {
        "id": "zZMKba-k2-vU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "cphhkPx9KeSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_text = re.sub(r'\\[[0-9]*\\]', ' ', corpus_text)\n",
        "corpus_text = re.sub(r'\\s+', ' ', corpus_text)"
      ],
      "metadata": {
        "id": "8a4-_SYN6yiY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_sentences = nltk.sent_tokenize(corpus_text)\n",
        "corpus_words = nltk.word_tokenize(corpus_text)"
      ],
      "metadata": {
        "id": "iSb3EQkt7Tqn"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Greet Function"
      ],
      "metadata": {
        "id": "9DhtzyPFKhWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "greeting_inputs = ['hey', 'hello', 'good morning', 'ssup?']\n",
        "greeting_responses = ['hey', 'How are you', 'Hi', 'Whatsup']\n",
        "\n",
        "def greet_response(greeting):\n",
        "  for token in greeting.split():\n",
        "    if token.lower() in greeting_inputs:\n",
        "      return random.choice(greeting_responses)\n"
      ],
      "metadata": {
        "id": "v1bWh_Uw8_-9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatizing"
      ],
      "metadata": {
        "id": "aQUqpbOUKkan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_corpus(tokens):\n",
        "  return [wn_lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "punct_removal_dict = dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
        "\n",
        "def get_processed_text(document):\n",
        "  return lemmatize_corpus(nltk.word_tokenize(document.lower().translate(punct_removal_dict)))"
      ],
      "metadata": {
        "id": "BuEYPQLX9zRM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF Vectorizer"
      ],
      "metadata": {
        "id": "e05XR3DAKnAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def respond(user_input):\n",
        "  bot_response = ''\n",
        "  corpus_sentences.append(user_input)\n",
        "\n",
        "  word_vectorizer = TfidfVectorizer(tokenizer = get_processed_text, stop_words = 'english')\n",
        "  corpus_word_vectors = word_vectorizer.fit_transform(corpus_sentences)\n",
        "\n",
        "  cos_sim_vectors = cosine_similarity(corpus_word_vectors[-1], corpus_word_vectors)\n",
        "  similar_response_idx = cos_sim_vectors.argsort()[0][-2]\n",
        "\n",
        "  matched_vector = cos_sim_vectors.flatten()\n",
        "  matched_vector.sort()\n",
        "  vector_matched = matched_vector[-2]\n",
        "\n",
        "  if vector_matched == 0:\n",
        "    bot_response = bot_response + 'Sorry! I dont understand'\n",
        "    return bot_response\n",
        "\n",
        "  else:\n",
        "    bot_response = bot_response + corpus_sentences[similar_response_idx]\n",
        "    return bot_response"
      ],
      "metadata": {
        "id": "DCYD-FVEADq3"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing ChatBox"
      ],
      "metadata": {
        "id": "0uWej77GKrmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = True\n",
        "print('Hello! What do you want to learn about cuisines today?')\n",
        "\n",
        "while(chat ==  True):\n",
        "  user_query = input()\n",
        "  #user_query = user_query.lower()\n",
        "  if user_query != 'quit':\n",
        "    if user_query == 'thanks' or user_query == 'thank you':\n",
        "      chat = False\n",
        "      print('You are welcome!')\n",
        "    else:\n",
        "      greet_response(user_query)\n",
        "      if greet_response(user_query) != None:\n",
        "        print('True!')\n",
        "        print('CuisineBost: ' + greet_response(user_query))\n",
        "      else:\n",
        "        print('Found none input')\n",
        "        print('CuisineBot: ', end='')\n",
        "        print(respond(user_query))\n",
        "        corpus_sentences.remove(user_query)\n",
        "  else:\n",
        "    chat = False\n",
        "    print('CuisineBot: Good Bye')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cce1ZaWQGe55",
        "outputId": "4d8ed10b-9117-497e-b48f-0ab4a0ab0dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! What do you want to learn about cuisines today?\n",
            "Hi\n",
            "Found none input\n",
            "CuisineBot: Sorry! I dont understand\n",
            "Hi\n",
            "Found none input\n",
            "CuisineBot: Sorry! I dont understand\n",
            "hey\n",
            "True!\n",
            "CuisineBost: hey\n",
            "hey\n",
            "True!\n",
            "CuisineBost: Whatsup\n",
            "food\n",
            "Found none input\n",
            "CuisineBot: market stalls selling food are found across southeast asia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ySizRqsyIROd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}